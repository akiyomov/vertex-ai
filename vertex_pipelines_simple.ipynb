{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pknVo1kM2wI2"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoFqANDE222Y"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x1ypzczQCwy"
   },
   "source": [
    "# Simple TFX Pipeline for Vertex Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_445qeKq8e3-"
   },
   "source": [
    "<div class=\"devsite-table-wrapper\"><table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "<td><a target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_simple\">\n",
    "<img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"/>View on TensorFlow.org</a></td>\n",
    "<td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/gcp/vertex_pipelines_simple.ipynb\">\n",
    "<img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a></td>\n",
    "<td><a target=\"_blank\" href=\"https://github.com/tensorflow/tfx/tree/master/docs/tutorials/tfx/gcp/vertex_pipelines_simple.ipynb\">\n",
    "<img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a></td>\n",
    "<td><a href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/tfx/gcp/vertex_pipelines_simple.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a></td>\n",
    "<td><a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?q=download_url%3Dhttps%253A%252F%252Fraw.githubusercontent.com%252Ftensorflow%252Ftfx%252Fmaster%252Fdocs%252Ftutorials%252Ftfx%252Fgcp%252Fvertex_pipelines_simple.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Run in Google Cloud Vertex AI Workbench</a></td>\n",
    "</table></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VuwrlnvQJ5k"
   },
   "source": [
    "This notebook-based tutorial will create a simple TFX pipeline and run it using\n",
    "Google Cloud Vertex Pipelines.  This notebook is based on the TFX pipeline\n",
    "we built in\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "If you are not familiar with TFX and you have not read that tutorial yet, you\n",
    "should read it before proceeding with this notebook.\n",
    "\n",
    "Google Cloud Vertex Pipelines helps you to automate, monitor, and govern\n",
    "your ML systems by orchestrating your ML workflow in a serverless manner. You\n",
    "can define your ML pipelines using Python with TFX, and then execute your\n",
    "pipelines on Google Cloud. See\n",
    "[Vertex Pipelines introduction](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)\n",
    "to learn more about Vertex Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4U5gp15QJ2b"
   },
   "source": [
    "This notebook is intended to be run on\n",
    "[Google Colab](https://colab.research.google.com/notebooks/intro.ipynb) or on\n",
    "[AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks). If you\n",
    "are not using one of these, you can simply click \"Run in Google Colab\" button\n",
    "above.\n",
    "\n",
    "## Set up\n",
    "Before you run this notebook, ensure that you have following:\n",
    "- A [Google Cloud Platform](http://cloud.google.com/) project.\n",
    "- A [Google Cloud Storage](https://cloud.google.com/storage) bucket. See\n",
    "[the guide for creating buckets](https://cloud.google.com/storage/docs/creating-buckets).\n",
    "- Enable\n",
    "[Vertex AI and Cloud Storage API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,storage-component.googleapis.com).\n",
    "\n",
    "Please see\n",
    "[Vertex documentation](https://cloud.google.com/vertex-ai/docs/pipelines/configure-project)\n",
    "to configure your GCP project further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwZ0aXisoBFW"
   },
   "source": [
    "### Install python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC9W_S-bONgl"
   },
   "source": [
    "We will install required Python packages including TFX and KFP to author ML\n",
    "pipelines and submit jobs to Vertex Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iyQtljP-qPHY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "Collecting tfx<2 (from tfx[kfp]<2)\n",
      "  Downloading tfx-1.14.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting ml-pipelines-sdk==1.14.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading ml_pipelines_sdk-1.14.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.4.0)\n",
      "Collecting ml-metadata<1.15.0,>=1.14.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading ml_metadata-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting packaging<21,>=20 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portpicker<2,>=1.3.1 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf<5,>=3.20.3 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting docker<5,>=4.1 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-apitools<1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (0.5.31)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.8 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.8.0)\n",
      "Requirement already satisfied: jinja2<4,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (4.8.0)\n",
      "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading apache_beam-2.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting attrs<22,>=19.3.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (8.1.7)\n",
      "Requirement already satisfied: google-api-core<3 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.36.0)\n",
      "Collecting google-cloud-bigquery<3,>=2.26.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_cloud_bigquery-2.34.4-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.28.1 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.48.1)\n",
      "Requirement already satisfied: keras-tuner<2,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.4.5)\n",
      "Collecting kubernetes<13,>=10.0.1 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.16 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (1.24.4)\n",
      "Collecting pyarrow<11,>=10 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=6 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (6.0.1)\n",
      "Collecting tensorflow<2.14,>=2.13.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting tensorflow-hub<0.14,>=0.9.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-data-validation<1.15.0,>=1.14.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_data_validation-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tensorflow-model-analysis<0.46.0,>=0.45.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_model_analysis-0.45.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15 in /opt/conda/lib/python3.10/site-packages (from tfx<2->tfx[kfp]<2) (2.11.0)\n",
      "Collecting tensorflow-transform<1.15.0,>=1.14.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_transform-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tfx-bsl<1.15.0,>=1.14.0 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tfx_bsl-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting kfp<2,>=1.8.14 (from tfx[kfp]<2)\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2,>=0.1.10 (from tfx[kfp]<2)\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.9.10)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (1.9.0)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.19)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.21.0)\n",
      "Collecting js2py<1,>=0.74 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.6.1)\n",
      "INFO: pip is looking at multiple versions of apache-beam to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading apache_beam-2.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (1.22.3)\n",
      "Collecting protobuf<5,>=3.20.3 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2023.3.post1)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2023.10.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.31.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.22.0)\n",
      "INFO: pip is looking at multiple versions of apache-beam[gcp] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: cachetools<6,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (4.2.4)\n",
      "Collecting google-api-core<3 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_api_core-2.14.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.23.4)\n",
      "Requirement already satisfied: google-auth-httplib2<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.1.1)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_cloud_datastore-2.18.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: google-cloud-pubsub<3,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.18.4)\n",
      "Requirement already satisfied: google-cloud-pubsublite<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (1.8.3)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.16.2)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (2.3.3)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_cloud_bigtable-2.21.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.40.1)\n",
      "Requirement already satisfied: google-cloud-dlp<4,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.13.0)\n",
      "Collecting google-cloud-language<3,>=2.0 (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_cloud_language-2.11.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_cloud_videointelligence-2.11.4-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-cloud-vision<4,>=2 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.4.5)\n",
      "Requirement already satisfied: google-cloud-recommendations-ai<0.11.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.7.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker<5,>=4.1->tfx<2->tfx[kfp]<2) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker<5,>=4.1->tfx<2->tfx[kfp]<2) (1.6.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3->tfx<2->tfx[kfp]<2) (1.61.0)\n",
      "INFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-python-client<2,>=1.8 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client<2,>=1.8->tfx<2->tfx[kfp]<2) (3.0.1)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from google-apitools<1,>=0.5->tfx<2->tfx[kfp]<2) (4.1.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx<2->tfx[kfp]<2) (2.13.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx<2->tfx[kfp]<2) (1.10.4)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx<2->tfx[kfp]<2) (2.0.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<3,>=2.26.0->tfx<2->tfx[kfp]<2) (2.6.0)\n",
      "Collecting protobuf<5,>=3.20.3 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<4,>=2.7.3->tfx<2->tfx[kfp]<2) (2.0.1)\n",
      "Requirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (from keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (0.1.7)\n",
      "Requirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (1.0.5)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (0.10.1)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (4.19.2)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (0.9.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (1.2.14)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (0.15)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (1.26.18)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (1.10.13)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]<2) (0.9.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx<2->tfx[kfp]<2) (2023.7.22)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx<2->tfx[kfp]<2) (68.2.2)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx<2->tfx[kfp]<2) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<21,>=20->tfx<2->tfx[kfp]<2) (3.1.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker<2,>=1.3.1->tfx<2->tfx[kfp]<2) (5.9.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (3.10.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (16.0.6)\n",
      "Collecting numpy<2,>=1.16 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (3.3.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (2.3.0)\n",
      "Collecting typing-extensions<5,>=3.10.0.2 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (0.29.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx<2->tfx[kfp]<2) (1.3.2)\n",
      "Collecting pandas<2,>=1.0 (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.9/99.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-metadata<1.15,>=1.14.0 (from tensorflow-data-validation<1.15.0,>=1.14.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting ipython<8,>=7 (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets<8,>=7 (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading ipywidgets-7.8.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pillow>=9.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (10.0.1)\n",
      "Requirement already satisfied: scipy<2,>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.11.3)\n",
      "INFO: pip is looking at multiple versions of tensorflow-serving-api to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorflow_serving_api-2.14.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading tensorflow_serving_api-2.13.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (0.41.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2,>=1.6.2->tfx<2->tfx[kfp]<2) (1.48.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.12.6)\n",
      "Collecting grpcio<2,>=1.28.1 (from tfx<2->tfx[kfp]<2)\n",
      "  Downloading grpcio-1.59.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: overrides<7.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (6.5.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.4.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2,>=1.6.2->tfx<2->tfx[kfp]<2) (1.5.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.19.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (5.13.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (3.0.39)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.16.1)\n",
      "Collecting backcall (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.1.4)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.2.0)\n",
      "Collecting widgetsnbextension~=3.6.6 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting jupyterlab-widgets<3,>=1.0.0 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading jupyterlab_widgets-1.1.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonschema<5,>=3.0.1 (from kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading jsonschema-4.20.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading jsonschema-4.19.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading jsonschema-4.19.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "  Downloading jsonschema-4.18.6-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading jsonschema-4.18.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading jsonschema-4.18.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading jsonschema-4.18.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "INFO: pip is still looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading jsonschema-4.18.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading jsonschema-4.18.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading jsonschema-4.18.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<5,>=3.0.1->kfp<2,>=1.8.14->tfx[kfp]<2)\n",
      "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=1.4.12->google-apitools<1,>=0.5->tfx<2->tfx[kfp]<2) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx<2->tfx[kfp]<2) (3.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (3.5.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tfx<2->tfx[kfp]<2) (2.1.2)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (13.6.0)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (0.1.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx<2->tfx[kfp]<2) (3.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.2.9)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (6.5.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core->keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner<2,>=1.0.4->tfx<2->tfx[kfp]<2) (0.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (6.3.3)\n",
      "Requirement already satisfied: pyzmq<25,>=17 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (24.0.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (23.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (5.5.0)\n",
      "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (7.4.9)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (5.9.2)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (7.10.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.5.8)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (6.26.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.18.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.0.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client<8,>=5.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (3.11.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.9.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.18.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (21.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.8.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (3.7.1)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.4.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.1.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.0.7)\n",
      "Requirement already satisfied: referencing in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.30.2)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (0.1.1)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting jupyter-events>=0.6.0 (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2)\n",
      "  Downloading jupyter_events-0.9.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading jupyter_events-0.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading jupyter_events-0.7.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of jsonschema[format-nongpl] to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is still looking at multiple versions of jsonschema[format-nongpl] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.4)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets<8,>=7->tensorflow-model-analysis<0.46.0,>=0.45.0->tfx<2->tfx[kfp]<2) (2.8.19.14)\n",
      "Downloading tfx-1.14.0-py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_pipelines_sdk-1.14.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading apache_beam-2.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.14.0-py3-none-any.whl (122 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_metadata-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_data_validation-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_model_analysis-0.45.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_serving_api-2.13.1-py2.py3-none-any.whl (26 kB)\n",
      "Downloading tensorflow_transform-1.14.0-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m819.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tfx_bsl-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigtable-2.21.0-py2.py3-none-any.whl (293 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.0/293.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_datastore-2.18.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.3/177.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_language-2.11.1-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.59.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_videointelligence-2.11.4-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-7.8.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading jupyterlab_widgets-1.1.7-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.4/295.4 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kfp, fire, kfp-server-api, pyfarmhash, strip-hints\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426965 sha256=cd2300ddee06aa1505a6951ec565f42edd58c96fa48a33896f4dff0866e3b19d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116933 sha256=49bb106683bc243220fbe5ba326f75ce7ee0114215cae2ab9f142917b0577461\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99697 sha256=403be9e5d694ea25644f6008be3dd998094ac3b7a172cfb7e3a53e1e05083a24\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c5/97/d5/e8a0f596dc85f5cfe383c800fbf3e29a99853bb54e01f26fca\n",
      "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=13876 sha256=d632036904f5bede6aca32ba562ba35822ae4d5b541b6c53b87822cff215e950\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22284 sha256=e9ec0759ca73ddc88fd6064e37104b4f7f85292f6c546d81b374c9be3a24b02d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/19/fd/dc/1192a4b454695fa9f0c95b17597a44b200d9fcf0eeb771d104\n",
      "Successfully built kfp fire kfp-server-api pyfarmhash strip-hints\n",
      "Installing collected packages: pyfarmhash, backcall, typing-extensions, tensorflow-estimator, tensorboard-data-server, strip-hints, pyrsistent, protobuf, portpicker, packaging, numpy, keras, jupyterlab-widgets, grpcio, fire, attrs, tensorflow-hub, pyarrow, pandas, ml-metadata, kfp-server-api, kfp-pipeline-spec, jsonschema, ipython, docker, tensorflow-metadata, kubernetes, google-auth-oauthlib, google-api-core, apache-beam, tensorboard, google-api-python-client, tensorflow, ml-pipelines-sdk, jupyter-events, google-cloud-videointelligence, google-cloud-language, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery, tensorflow-serving-api, kfp, tfx-bsl, tensorflow-transform, tensorflow-data-validation, widgetsnbextension, ipywidgets, tensorflow-model-analysis, tfx\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.11.0\n",
      "    Uninstalling tensorflow-estimator-2.11.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: jupyterlab-widgets\n",
      "    Found existing installation: jupyterlab-widgets 3.0.9\n",
      "    Uninstalling jupyterlab-widgets-3.0.9:\n",
      "      Successfully uninstalled jupyterlab-widgets-3.0.9\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.48.1\n",
      "    Uninstalling grpcio-1.48.1:\n",
      "      Successfully uninstalled grpcio-1.48.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: tensorflow-hub\n",
      "    Found existing installation: tensorflow-hub 0.15.0\n",
      "    Uninstalling tensorflow-hub-0.15.0:\n",
      "      Successfully uninstalled tensorflow-hub-0.15.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 9.0.0\n",
      "    Uninstalling pyarrow-9.0.0:\n",
      "      Successfully uninstalled pyarrow-9.0.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: kfp-server-api\n",
      "    Found existing installation: kfp-server-api 2.0.3\n",
      "    Uninstalling kfp-server-api-2.0.3:\n",
      "      Successfully uninstalled kfp-server-api-2.0.3\n",
      "  Attempting uninstall: kfp-pipeline-spec\n",
      "    Found existing installation: kfp-pipeline-spec 0.2.2\n",
      "    Uninstalling kfp-pipeline-spec-0.2.2:\n",
      "      Successfully uninstalled kfp-pipeline-spec-0.2.2\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.2\n",
      "    Uninstalling jsonschema-4.19.2:\n",
      "      Successfully uninstalled jsonschema-4.19.2\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.17.2\n",
      "    Uninstalling ipython-8.17.2:\n",
      "      Successfully uninstalled ipython-8.17.2\n",
      "  Attempting uninstall: docker\n",
      "    Found existing installation: docker 6.1.3\n",
      "    Uninstalling docker-6.1.3:\n",
      "      Successfully uninstalled docker-6.1.3\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~ocker'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: tensorflow-metadata\n",
      "    Found existing installation: tensorflow-metadata 0.14.0\n",
      "    Uninstalling tensorflow-metadata-0.14.0:\n",
      "      Successfully uninstalled tensorflow-metadata-0.14.0\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 26.1.0\n",
      "    Uninstalling kubernetes-26.1.0:\n",
      "      Successfully uninstalled kubernetes-26.1.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.0\n",
      "    Uninstalling google-api-core-1.34.0:\n",
      "      Successfully uninstalled google-api-core-1.34.0\n",
      "  Attempting uninstall: apache-beam\n",
      "    Found existing installation: apache-beam 2.46.0\n",
      "    Uninstalling apache-beam-2.46.0:\n",
      "      Successfully uninstalled apache-beam-2.46.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.2\n",
      "    Uninstalling tensorboard-2.11.2:\n",
      "      Successfully uninstalled tensorboard-2.11.2\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 1.8.0\n",
      "    Uninstalling google-api-python-client-1.8.0:\n",
      "      Successfully uninstalled google-api-python-client-1.8.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.11.0\n",
      "    Uninstalling tensorflow-2.11.0:\n",
      "      Successfully uninstalled tensorflow-2.11.0\n",
      "  Attempting uninstall: jupyter-events\n",
      "    Found existing installation: jupyter-events 0.8.0\n",
      "    Uninstalling jupyter-events-0.8.0:\n",
      "      Successfully uninstalled jupyter-events-0.8.0\n",
      "  Attempting uninstall: google-cloud-videointelligence\n",
      "    Found existing installation: google-cloud-videointelligence 1.16.3\n",
      "    Uninstalling google-cloud-videointelligence-1.16.3:\n",
      "      Successfully uninstalled google-cloud-videointelligence-1.16.3\n",
      "  Attempting uninstall: google-cloud-language\n",
      "    Found existing installation: google-cloud-language 1.3.2\n",
      "    Uninstalling google-cloud-language-1.3.2:\n",
      "      Successfully uninstalled google-cloud-language-1.3.2\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.15.5\n",
      "    Uninstalling google-cloud-datastore-1.15.5:\n",
      "      Successfully uninstalled google-cloud-datastore-1.15.5\n",
      "  Attempting uninstall: google-cloud-bigtable\n",
      "    Found existing installation: google-cloud-bigtable 1.7.3\n",
      "    Uninstalling google-cloud-bigtable-1.7.3:\n",
      "      Successfully uninstalled google-cloud-bigtable-1.7.3\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 3.13.0\n",
      "    Uninstalling google-cloud-bigquery-3.13.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-3.13.0\n",
      "  Attempting uninstall: tensorflow-serving-api\n",
      "    Found existing installation: tensorflow-serving-api 2.11.0\n",
      "    Uninstalling tensorflow-serving-api-2.11.0:\n",
      "      Successfully uninstalled tensorflow-serving-api-2.11.0\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 2.4.0\n",
      "    Uninstalling kfp-2.4.0:\n",
      "      Successfully uninstalled kfp-2.4.0\n",
      "  Attempting uninstall: tensorflow-transform\n",
      "    Found existing installation: tensorflow-transform 0.14.0\n",
      "    Uninstalling tensorflow-transform-0.14.0:\n",
      "      Successfully uninstalled tensorflow-transform-0.14.0\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 4.0.9\n",
      "    Uninstalling widgetsnbextension-4.0.9:\n",
      "      Successfully uninstalled widgetsnbextension-4.0.9\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 8.1.1\n",
      "    Uninstalling ipywidgets-8.1.1:\n",
      "      Successfully uninstalled ipywidgets-8.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.11 which is incompatible.\n",
      "fastapi 0.104.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "jupyterlab-server 2.25.0 requires jsonschema>=4.18.0, but you have jsonschema 4.17.3 which is incompatible.\n",
      "jupyterlab-server 2.25.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
      "referencing 0.30.2 requires attrs>=22.2.0, but you have attrs 21.4.0 which is incompatible.\n",
      "scikit-image 0.22.0 requires packaging>=21, but you have packaging 20.9 which is incompatible.\n",
      "statsmodels 0.14.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
      "typeguard 4.1.5 requires typing-extensions>=4.7.0; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed apache-beam-2.50.0 attrs-21.4.0 backcall-0.2.0 docker-4.4.4 fire-0.5.0 google-api-core-2.11.1 google-api-python-client-1.12.11 google-auth-oauthlib-1.0.0 google-cloud-bigquery-2.34.4 google-cloud-bigtable-2.21.0 google-cloud-datastore-1.15.5 google-cloud-language-2.11.1 google-cloud-videointelligence-2.11.4 grpcio-1.59.2 ipython-7.34.0 ipywidgets-7.8.1 jsonschema-4.17.3 jupyter-events-0.6.3 jupyterlab-widgets-1.1.7 keras-2.13.1 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-12.0.1 ml-metadata-1.14.0 ml-pipelines-sdk-1.14.0 numpy-1.24.3 packaging-20.9 pandas-1.5.3 portpicker-1.6.0 protobuf-3.20.3 pyarrow-10.0.1 pyfarmhash-0.3.2 pyrsistent-0.20.0 strip-hints-0.1.10 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-data-validation-1.14.0 tensorflow-estimator-2.13.0 tensorflow-hub-0.13.0 tensorflow-metadata-1.14.0 tensorflow-model-analysis-0.45.0 tensorflow-serving-api-2.13.1 tensorflow-transform-1.14.0 tfx-1.14.0 tfx-bsl-1.14.0 typing-extensions-4.5.0 widgetsnbextension-3.6.6\n"
     ]
    }
   ],
   "source": [
    "# Use the latest version of pip.\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade \"tfx[kfp]<2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGJoLWD6kJu2"
   },
   "source": [
    "### Uninstall shapely\n",
    "\n",
    "TODO(b/263441833) This is a temporal solution to avoid an\n",
    "ImportError. Ultimately, it should be handled by supporting a\n",
    "recent version of Bigquery, instead of uninstalling other extra\n",
    "dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lVkGjRNQkKFe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: shapely 2.0.2\n",
      "Uninstalling shapely-2.0.2:\n",
      "  Successfully uninstalled shapely-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall shapely -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwT0nov5QO1M"
   },
   "source": [
    "#### Did you restart the runtime?\n",
    "\n",
    "If you are using Google Colab, the first time that you run\n",
    "the cell above, you must restart the runtime by clicking\n",
    "above \"RESTART RUNTIME\" button or using \"Runtime > Restart\n",
    "runtime ...\" menu. This is because of the way that Colab\n",
    "loads packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CRyIL4LVDlQ"
   },
   "source": [
    "If you are not on Colab, you can restart runtime with following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KHTSzMygoBF6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "import sys\n",
    "if not 'google.colab' in sys.modules:\n",
    "  # Automatically restart kernel after installs\n",
    "  import IPython\n",
    "  app = IPython.Application.instance()\n",
    "  app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gckGHdW9iPrq"
   },
   "source": [
    "### Login in to Google for this notebook\n",
    "If you are running this notebook on Colab, authenticate with your user account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kZQA0KrfXCvU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaqJjbmk6o0o"
   },
   "source": [
    "**If you are on AI Platform Notebooks**, authenticate with Google Cloud before\n",
    "running the next section, by running\n",
    "```sh\n",
    "gcloud auth login\n",
    "```\n",
    "**in the Terminal window** (which you can open via **File** > **New** in the\n",
    "menu). You only need to do this once per notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_SveIKxaENu"
   },
   "source": [
    "Check the package versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Xd-iP9wEaENu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 00:15:21.145308: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "TFX version: 1.14.0\n",
      "KFP version: 1.8.22\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "import kfp\n",
    "print('KFP version: {}'.format(kfp.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EcUseqJaE2XN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'steam-house-386308'     # <--- ENTER THIS\n",
    "GOOGLE_CLOUD_REGION = 'asia-northeast3'      # <--- ENTER THIS\n",
    "GCS_BUCKET_NAME = 'palmer-penguin'          # <--- ENTER THIS\n",
    "\n",
    "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
    "    from absl import logging\n",
    "    logging.error('Please set all required parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAaCPLjgiJrO"
   },
   "source": [
    "Set `gcloud` to use your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VkWdxe4TXRHk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project {GOOGLE_CLOUD_PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CPN6UL5CazNy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://palmer-penguin/pipeline_root/penguin-vertex-pipelines\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME = 'penguin-vertex-pipelines'\n",
    "\n",
    "# Path to various pipeline artifact.\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' Python module.\n",
    "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for input data.\n",
    "DATA_ROOT = 'gs://{}/data/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "SERVING_MODEL_DIR = 'gs://{}/serving_model/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F2SRwRLSYGa"
   },
   "source": [
    "### Prepare example data\n",
    "We will use the same\n",
    "[Palmer Penguins dataset](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)\n",
    "as\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "\n",
    "There are four numeric features in this dataset which were already normalized\n",
    "to have range [0,1]. We will build a classification model which predicts the\n",
    "`species` of penguins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11J7XiCq6AFP"
   },
   "source": [
    "We need to make our own copy of the dataset. Because TFX ExampleGen reads\n",
    "inputs from a directory, we need to create a directory and copy dataset to it\n",
    "on GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4fxMs6u86acP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 25.0 KiB/ 25.0 KiB]                                                \n",
      "Operation completed over 1 objects/25.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv {DATA_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASpoNmxKSQjI"
   },
   "source": [
    "Take a quick look at the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-eSz28UDSnlG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\n",
      "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\n",
      "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\n",
      "0,0.29818181818181805,0.5833333333333334,0.3898305084745763,0.1527777777777778\n",
      "0,0.16727272727272732,0.7380952380952381,0.3559322033898305,0.20833333333333334\n",
      "0,0.26181818181818167,0.892857142857143,0.3050847457627119,0.2638888888888889\n",
      "0,0.24727272727272717,0.5595238095238096,0.15254237288135594,0.2569444444444444\n",
      "0,0.25818181818181823,0.773809523809524,0.3898305084745763,0.5486111111111112\n",
      "0,0.32727272727272727,0.5357142857142859,0.1694915254237288,0.1388888888888889\n",
      "0,0.23636363636363636,0.9642857142857142,0.3220338983050847,0.3055555555555556\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {DATA_ROOT}/penguins_processed.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH6gizcpSwWV"
   },
   "source": [
    "## Create a pipeline\n",
    "\n",
    "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
    "consists of three components, CsvExampleGen, Trainer and Pusher. The pipeline\n",
    "and model definition is almost the same as\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "\n",
    "The only difference is that we don't need to set `metadata_connection_config`\n",
    "which is used to locate\n",
    "[ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) database. Because\n",
    "Vertex Pipelines uses a managed metadata service, users don't need to care\n",
    "of it, and we don't need to specify the parameter.\n",
    "\n",
    "Before actually define the pipeline, we need to write a model code for the\n",
    "Trainer component first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOjDv93eS5xV"
   },
   "source": [
    "### Write model code.\n",
    "\n",
    "We will use the same model code as in the\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aES7Hv5QTDK3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_trainer_module_file = 'penguin_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Gnc67uQNTDfW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguin_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "_FEATURE_KEYS = [\n",
    "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
    "]\n",
    "_LABEL_KEY = 'species'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 20\n",
    "_EVAL_BATCH_SIZE = 10\n",
    "\n",
    "# Since we're not generating or creating a schema, we will instead create\n",
    "# a feature spec.  Since there are a fairly small number of features this is\n",
    "# manageable for this dataset.\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "           for feature in _FEATURE_KEYS\n",
    "       },\n",
    "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    schema: schema of the input data.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "  # The model below is built with Functional API, please refer to\n",
    "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
    "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
    "  d = keras.layers.concatenate(inputs)\n",
    "  for _ in range(2):\n",
    "    d = keras.layers.Dense(8, activation='relu')(d)\n",
    "  outputs = keras.layers.Dense(3)(d)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(1e-2),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  model.summary(print_fn=logging.info)\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
    "  # version provided by pipeline author. A schema can also derived from TFT\n",
    "  # graph if a Transform component is used. In the case when either is missing,\n",
    "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
    "  # feature_spec, but the schema returned would be very primitive.\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _make_keras_model()\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LsYx8MpYvPv"
   },
   "source": [
    "Copy the module file to GCS which can be accessed from the pipeline components.\n",
    "Because model training happens on GCP, we need to upload this model definition. \n",
    "\n",
    "Otherwise, you might want to build a container image including the module file\n",
    "and use the image to run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rMMs5wuNYAbc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://penguin_trainer.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
      "Operation completed over 1 objects/3.8 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {_trainer_module_file} {MODULE_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OkNz3gTLwM"
   },
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "We will define a function to create a TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M49yYVNBTPd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple and\n",
    "# slightly modified because we don't need `metadata_path` argument.\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJbq07THU2GV"
   },
   "source": [
    "## Run the pipeline on Vertex Pipelines.\n",
    "\n",
    "We used `LocalDagRunner` which runs on local environment in\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "TFX provides multiple orchestrators to run your pipeline. In this tutorial we\n",
    "will use the Vertex Pipelines together with the Kubeflow V2 dag runner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mp0AkmrPdUb"
   },
   "source": [
    "We need to define a runner to actually run the pipeline. You will compile\n",
    "your pipeline into our pipeline definition format using TFX APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fAtfOZTYWJu-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Generating ephemeral wheel package for '/var/tmp/tmpe3_hj8qk/penguin_trainer.py' (including modules: ['penguin_trainer']).\n",
      "INFO:absl:User module package has hash fingerprint version afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python', '/var/tmp/tmp2daxligj/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmp8vsufvmg', '--dist-dir', '/var/tmp/tmpukokn0_3']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying penguin_trainer.py -> build/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing to /var/tmp/tmp8vsufvmg\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/penguin_trainer.py -> /var/tmp/tmp8vsufvmg\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmp8vsufvmg/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmp8vsufvmg/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpukokn0_3/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3-none-any.whl' and adding '/var/tmp/tmp8vsufvmg' to it\n",
      "adding 'penguin_trainer.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/RECORD'\n",
      "removing /var/tmp/tmp8vsufvmg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully built user code wheel distribution at 'gs://palmer-penguin/pipeline_root/penguin-vertex-pipelines/_wheels/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3-none-any.whl'; target user module is 'penguin_trainer'.\n",
      "INFO:absl:Full user module path is 'penguin_trainer@gs://palmer-penguin/pipeline_root/penguin-vertex-pipelines/_wheels/tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3-none-any.whl'\n"
     ]
    }
   ],
   "source": [
    "# docs_infra: no_execute\n",
    "import os\n",
    "\n",
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "# Following function will write the pipeline definition to PIPELINE_DEFINITION_FILE.\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
    "        serving_model_dir=SERVING_MODEL_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWyITYSDd8w4"
   },
   "source": [
    "The generated definition file can be submitted using kfp client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tI71jlEvWMV7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/321949238924/locations/asia-northeast3/pipelineJobs/penguin-vertex-pipelines-20231117031620\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/321949238924/locations/asia-northeast3/pipelineJobs/penguin-vertex-pipelines-20231117031620')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-northeast3/pipelines/runs/penguin-vertex-pipelines-20231117031620?project=321949238924\n"
     ]
    }
   ],
   "source": [
    "# docs_infra: no_execute\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3k9f5IVQXcQ"
   },
   "source": [
    "Now you can visit the link in the output above or visit 'Vertex AI > Pipelines'\n",
    "in [Google Cloud Console](https://console.cloud.google.com/) to see the\n",
    "progress."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pknVo1kM2wI2"
   ],
   "name": "Simple TFX Pipeline for Vertex Pipelines",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
